{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "wyP0uAvIsF00",
      "metadata": {
        "id": "wyP0uAvIsF00"
      },
      "source": [
        "<link rel=\"stylesheet\" href=\"berkeley.css\">\n",
        "\n",
        "<h1 class=\"cal cal-h1\">Lecture 02 – CS 189, Fall 2025</h1>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ac1959f",
      "metadata": {},
      "source": [
        "In this notebook, we will cover the fundamental concepts and essential techniques for using `pandas` effectively. We will start with creating and inspecting data structures, then move on to accessing, filtering, adding, modifying, sorting, aggregating, and handling missing data. By the end, you will have a solid foundation for performing data analysis tasks using `pandas`. In the second part of this notebook, we will look into visualization using `Matplotlib` and `plotly`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "464a42ae",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture \n",
        "import os\n",
        "import requests\n",
        "\n",
        "# Auto-download data files if they don't exist\n",
        "data_files = {\n",
        "    \"data/uc_berkeley_events.csv\": \"https://github.com/BerkeleyML/fa25-student/raw/main/lec/lec02/data/uc_berkeley_events.csv\",\n",
        "    \"data/Augmented_Landmarks_DataFrame.csv\": \"https://github.com/BerkeleyML/fa25-student/raw/main/lec/lec02/data/Augmented_Landmarks_DataFrame.csv\",\n",
        "}\n",
        "\n",
        "for local_path, url in data_files.items():\n",
        "    if not os.path.exists(local_path):\n",
        "        os.makedirs(os.path.dirname(local_path), exist_ok=True)\n",
        "        print(f\"Downloading {local_path}...\")\n",
        "        response = requests.get(url)\n",
        "        with open(local_path, 'wb') as f:\n",
        "            f.write(response.content)\n",
        "        print(f\"Downloaded {local_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff9dc534",
      "metadata": {},
      "source": [
        "## `pandas`\n",
        "\n",
        "`pandas` is a powerful and flexible open-source data analysis and manipulation tool, built on top of the Python programming language. It provides data structures like `DataFrames` and `Series`, and a rich set of functions for working with structured data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fsfwp3-msF01",
      "metadata": {
        "id": "fsfwp3-msF01"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZeNrNhm8sF02",
      "metadata": {
        "id": "ZeNrNhm8sF02"
      },
      "source": [
        "### Pandas Data Structures\n",
        "`Series`, `DataFrames`, and `Indices` are fundamental `pandas` data structures for storing tabular data and processing the data using vectorized operations.\n",
        "\n",
        "#### `DataFrame`\n",
        "Imagine a spreadsheet or a table with rows and columns. That's essentially what a `pandas` `DataFrame` is! It's a 2-dimensional data structure that can store data of different types in each column. Think of it as a collection of `Series` (which are like single columns in a spreadsheet) that share the same index (the row labels).\n",
        "\n",
        "`DataFrame`s are incredibly useful because they allow us to organize and work with structured data in a clear and efficient way. We can easily access, modify, and analyze data within a `DataFrame`, just like you would in a spreadsheet, but with the power of Python!\n",
        "\n",
        "We can create a `DataFrame` in different ways:\n",
        "##### 1. From a CSV File\n",
        "Use `pd.read_csv()` to load data from a CSV file into a `DataFrame`. You can specify options like `index_col`, `header`, and `na_values`.\n",
        "##### 2. From Scratch\n",
        "Manually define data and structure using `pd.DataFrame()` with lists, dictionaries, or other data structures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e88dbdd",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a DataFrame with event data from a CSV file\n",
        "event_data = pd.read_csv(\"data/uc_berkeley_events.csv\", index_col=\"Year\")\n",
        "event_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f2b97d7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8f2b97d7",
        "outputId": "9d2dbeed-75d0-4d62-b871-22e12652d7ac"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame with information about landmarks at UC Berkeley\n",
        "data = {\n",
        "    'Landmark': ['Sather Gate', 'Campanile', 'Doe Library', 'Memorial Glade', 'Sproul Plaza'],\n",
        "    'Type': ['Gate', 'Tower', 'Library', 'Open Space', 'Plaza'],\n",
        "    'Height': [30, 307, 80, 0, 0],\n",
        "    'Year Built': [1910, 1914, 1911, None, 1962]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2498fad2",
      "metadata": {},
      "source": [
        "#### `Series`\n",
        "A `Series` is a one-dimensional labeled array capable of holding any data type (integers, strings, floating-point numbers, etc.). It can be thought of as a single column of data, similar to a column in a spreadsheet or a database table. Each element in a `Series` is associated with an **index**, which acts as a label for that element.\n",
        "\n",
        "Below, we will create a `Series` object and explore its two main components:\n",
        "1. **Values**: The actual data stored in the `Series`.\n",
        "2. **Index**: The labels associated with each data point, which allow for easy access and manipulation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d3b8e71",
      "metadata": {},
      "outputs": [],
      "source": [
        "welcome_series = pd.Series([\"welcome\", \"to\", \"CS 189\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f00616df",
      "metadata": {},
      "outputs": [],
      "source": [
        "welcome_series.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b1f73bd",
      "metadata": {},
      "outputs": [],
      "source": [
        "welcome_series.values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd694557",
      "metadata": {
        "id": "cd694557"
      },
      "source": [
        "### Exploring `DataFrame`\n",
        "\n",
        "Understanding the structure and content of your `DataFrame` is an essential first step in data analysis. Here are some key methods to get a quick overview of your `DataFrame`:\n",
        "\n",
        "**View the first and last rows**:  \n",
        "- Use `.head()` to display the first few rows of the `DataFrame`.  \n",
        "- Use `.tail()` to display the last few rows.  \n",
        "\n",
        "**Inspect the structure**:  \n",
        "- Use `.info()` to get a summary of the `DataFrame`, including the number of rows, columns, data types, and memory usage.  \n",
        "\n",
        "**Get basic statistics**:  \n",
        "- Use `.describe()` to generate descriptive statistics for numeric columns, such as mean, standard deviation, and percentiles.  \n",
        "\n",
        "**Check dimensions and size**:  \n",
        "- Use `.shape` to get the number of rows and columns in the `DataFrame`.  \n",
        "- Use `.size` to get the total number of elements in the `DataFrame`.  \n",
        "\n",
        "**Random sampling**:  \n",
        "- Use `.sample()` to return a random sample of rows from the `DataFrame`.  \n",
        "\n",
        "**Analyze unique values and counts**:  \n",
        "- Use `.value_counts()` to count unique values in a column.  \n",
        "- Use `.unique()` to get an array of unique values in a column.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cddda68",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 823
        },
        "id": "7cddda68",
        "outputId": "04a33537-e370-412a-9f51-26604f7140e5"
      },
      "outputs": [],
      "source": [
        "# Display the first 5 rows\n",
        "display(df.head())\n",
        "\n",
        "# Display the last 3 rows\n",
        "display(df.tail(3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "858cd480",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get information about the DataFrame\n",
        "display(df.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa1b202d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get descriptive statistics\n",
        "display(df.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "546ce8bf",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the shape of the DataFrame\n",
        "print(\"Shape of df:\", df.shape)\n",
        "\n",
        "# Get the size of the DataFrame\n",
        "print(\"Size of df:\", df.size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f526513a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Randomly sample 2 rows from the DataFrame\n",
        "sampled_data = df.sample(n=2)\n",
        "display(sampled_data)\n",
        "\n",
        "# Randomly sample 40% of the rows from the DataFrame\n",
        "sampled_fraction = df.sample(frac=0.4)\n",
        "display(sampled_fraction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6820a55",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the count of unique values in the 'Type' column of df\n",
        "type_counts = df['Type'].value_counts()\n",
        "display(type_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6fc3792",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get unique values from the 'Type' column in the df DataFrame\n",
        "unique_types = df['Type'].unique()\n",
        "print(unique_types)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1bfc912",
      "metadata": {
        "id": "d1bfc912"
      },
      "source": [
        "### Selecting and Retrieving Data from a `DataFrame`\n",
        "\n",
        "When working with `DataFrame`s in `pandas`, there are several ways to select and retrieve data. Each method has its own use case and advantages. Below, we explain the three primary methods: `iloc[]`, `loc[]`, and context-dependent selection.\n",
        "\n",
        "#### **1. `iloc[]` - Integer-Location Based Indexing**\n",
        "- Use `iloc[]` when you want to select data based on the integer positions of rows and columns.\n",
        "- Think of it as using row and column numbers in a spreadsheet, starting from 0.\n",
        "- Examples:\n",
        "    - Select a specific cell: `df.iloc[0, 1]` (first row, second column).\n",
        "    - Select a range of rows and columns: `df.iloc[1:3, 0:2]`.\n",
        "\n",
        "#### **2. `loc[]` - Label-Based Indexing**\n",
        "- Use `loc[]` when you want to select data based on row and column labels.\n",
        "- If you haven't set a custom index, the default integer index will be used, making it similar to `iloc[]`.\n",
        "- If you have a custom index (e.g., names or dates), `loc[]` will use those labels.\n",
        "- Examples:\n",
        "    - Select a specific cell: `df.loc[0, 'Age']` (row with index `0`, column labeled `'Age'`).\n",
        "    - Select a range of rows and columns: `df.loc[1:3, 'Name':'City']`.\n",
        "\n",
        "#### **3. Context-Dependent Selection**\n",
        "- This method allows you to select data based on the context of your `DataFrame`.\n",
        "- You can directly use column names to select entire columns or slices of rows.\n",
        "- Examples:\n",
        "    - Select a single column: `df['Name']`.\n",
        "    - Select multiple columns: `df[['Name', 'Age']]`.\n",
        "    - Select a range of rows: `df[1:3]`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6ee1175",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Accessing an entry by integer location using iloc\n",
        "display(df.iloc[0, 1])  # Access the value in the first row and second column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af418277",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Accessing an entire column using iloc\n",
        "display(df.iloc[:, 1])  # Access all rows in the second column\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "H2DrcNSfv4Yh",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2DrcNSfv4Yh",
        "outputId": "e847405a-116e-423a-a5b2-e6b2cef7532c"
      },
      "outputs": [],
      "source": [
        "# Accessing an entire row using iloc\n",
        "display(df.iloc[0])  # Access all columns in the first row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PtdJ4BuDxLjW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtdJ4BuDxLjW",
        "outputId": "540ddce0-96b6-47dc-dc8e-17b7e4b3e390"
      },
      "outputs": [],
      "source": [
        "# Accessing a slice of rows using iloc\n",
        "display(df.iloc[1:3])  # Access rows 1 to 2 (exclusive of 3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sLCktuF_xmbQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "sLCktuF_xmbQ",
        "outputId": "569c2e3e-4e3e-4eb6-9b53-5a5eaa95f59d"
      },
      "outputs": [],
      "source": [
        "# Accessing a slice of columns using iloc\n",
        "display(df.iloc[:, 1:3])  # Access all rows for columns 1 to 2 (exclusive of 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sDboC2I-x5aG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "sDboC2I-x5aG",
        "outputId": "9a2b81f6-0487-4915-fb0b-e3ab161dd3e3"
      },
      "outputs": [],
      "source": [
        "# Accessing a specific range of rows and columns using iloc\n",
        "display(df.iloc[1:3, 1:3])  # Access rows 1 to 2 and columns 1 to 2 (exclusive of 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3GarsDUNyBCJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "3GarsDUNyBCJ",
        "outputId": "3246ae0a-9901-4f7b-e029-11daff9a4fa5"
      },
      "outputs": [],
      "source": [
        "# Accessing an entry by label using loc\n",
        "display(df.loc[0, 'Landmark'])  # Access the value in the first row and 'Landmark' column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Yh_7G68pyPKt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "Yh_7G68pyPKt",
        "outputId": "fe16f07f-3ad4-4602-cb7c-bbfcc480428e"
      },
      "outputs": [],
      "source": [
        "# Accessing an entire column using loc\n",
        "display(df.loc[:, 'Landmark'])  # Access all rows in the 'Landmark' column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89b61000",
      "metadata": {
        "id": "89b61000"
      },
      "outputs": [],
      "source": [
        "# Accessing an entire row using loc\n",
        "display(df.loc[0])  # Access all columns in the first row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc1a2550",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Accessing a slice of rows using loc\n",
        "display(df.loc[1:3])  # Access rows 1 to 3 (inclusive)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43ba5d19",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Accessing a slice of columns using loc\n",
        "display(df.loc[:, 'Landmark':'Height'])  # Access all rows for columns 'Landmark' to 'Height'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea7f47c9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Accessing a specific range of rows and columns using loc\n",
        "display(df.loc[1:3, 'Landmark':'Height'])  # Access rows 1 to 3 and columns 'Landmark' to 'Height'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b22faae9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Accessing a single column using context-dependent selection\n",
        "display(df['Year Built'])  # Access the 'Year Built' column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4225e49e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Accessing multiple columns using context-dependent selection\n",
        "display(df[['Landmark', 'Year Built']])  # Access the 'Landmark' and 'Year Built' columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c95024f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Accessing a slice of rows using context-dependent selection\n",
        "display(df[1:3])  # Access rows 1 to 2 (exclusive of 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2e7f817",
      "metadata": {
        "id": "e2e7f817"
      },
      "source": [
        "### Filtering Data in a `DataFrame`\n",
        "\n",
        "Filtering is a powerful technique in `pandas` that allows you to extract specific rows from your `DataFrame` based on conditions. This is particularly useful when you want to focus on a subset of your data that meets certain criteria.\n",
        "\n",
        "For example, you can filter rows where a column's value is greater than a threshold, matches a specific value, or satisfies multiple conditions. Filtering can also be combined with logical operators like `&` (AND), `|` (OR), and `~` (NOT) to create complex queries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08aa1bab",
      "metadata": {
        "id": "08aa1bab"
      },
      "outputs": [],
      "source": [
        "# Filter by a single condition\n",
        "display(df[df['Height'] > 50])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d296dc7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filter by multiple conditions\n",
        "display(df[(df['Height'] > 50) & (df['Type'] == 'Library')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96547131",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filter using isin()\n",
        "display(df[df['Type'].isin(['Gate', 'Plaza'])])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f3df7c7",
      "metadata": {
        "id": "3f3df7c7"
      },
      "source": [
        "### `DataFrame` Modification\n",
        "\n",
        "We can modify a `DataFrame` by:\n",
        "1. Add new columns.\n",
        "2. Perform calculations to create new data.\n",
        "3. Modify existing values in your `DataFrame`.\n",
        "4. Drop an existing column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fcf25f8",
      "metadata": {
        "id": "1fcf25f8"
      },
      "outputs": [],
      "source": [
        "# Add a new column\n",
        "df['Experience'] = [2, 5, 1, 8, 4]\n",
        "display(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "442a2da0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add a calculated column\n",
        "df['Height_Increase'] = df['Height'] * 0.10\n",
        "display(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65c85609",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Modify existing values using .loc[]\n",
        "df.loc[df['Landmark'] == 'Sather Gate', 'Height_Increase'] = 5\n",
        "display(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0c854e6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Drop the 'Experience' column from the DataFrame\n",
        "# Note: This operation does not modify the original DataFrame since inplace=False by default\n",
        "df.drop(columns=['Experience'])\n",
        "display(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f727edf",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Drop the 'Experience' column using the inplace parameter\n",
        "df.drop(columns=['Experience'], inplace=True)\n",
        "\n",
        "display(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32485016",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reassign the DataFrame to drop the 'Height_Increase' column\n",
        "df_dropped = df.drop(columns=['Height_Increase'])\n",
        "\n",
        "display(df_dropped)\n",
        "\n",
        "# Display the original DataFrame to show it remains unchanged after reassignment\n",
        "display(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87ef683c",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df_dropped\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "660dcffd",
      "metadata": {
        "id": "660dcffd"
      },
      "source": [
        "#### Sorting Your DataFrame\n",
        "Sorting organizes your data for better analysis. Use `sort_values()` to sort by one or more columns in ascending or descending order.\n",
        "\n",
        "- **Single column**: `df.sort_values(by='Column', ascending=True)`\n",
        "- **Multiple columns**: `df.sort_values(by=['Col1', 'Col2'], ascending=[True, False])`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c74ceb9",
      "metadata": {
        "id": "8c74ceb9"
      },
      "outputs": [],
      "source": [
        "# Sort by a single column\n",
        "display(df.sort_values(by='Height'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9ba7671",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sort by multiple columns\n",
        "display(df.sort_values(by=['Height', 'Type'], ascending=[True, False]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cd65b0a",
      "metadata": {},
      "source": [
        "#### Handling Missing Values in a DataFrame\n",
        "\n",
        "Missing values are a common issue in real-world datasets. Properly identifying and handling missing values is crucial for ensuring the accuracy and reliability of your analysis.\n",
        "\n",
        "We will explore techniques to:\n",
        "1. Detect missing values in a `DataFrame`.\n",
        "2. Quantify the extent of missing data.\n",
        "3. Handle missing values by either removing or imputing them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37bce068",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Introduce missing values\n",
        "df_missing = df.copy()\n",
        "df_missing.loc[0, 'Year Built'] = np.nan\n",
        "df_missing.loc[2, 'Height'] = np.nan\n",
        "df_missing.loc[4, 'Type'] = None\n",
        "display(df_missing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa19d1b0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "display(df_missing.isnull())\n",
        "\n",
        "# Count missing values per column\n",
        "display(df_missing.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e1b3240",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Drop rows with missing values\n",
        "display(df_missing.dropna())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "072d3f83",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fill missing values\n",
        "display(df_missing.fillna(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8eabc7e3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fills missing values in `df_missing` with defaults: mean for 'Year Built', median for 'Height', and 'Unknown' for 'Type', then displays the result.\n",
        "display(df_missing.fillna({'Year Built': df_missing['Year Built'].mean(), 'Height': df_missing['Height'].median(), 'Type': 'Unknown'}))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "199735c0",
      "metadata": {
        "id": "199735c0"
      },
      "source": [
        "### Aggregation in `DataFrame`\n",
        "\n",
        "We can perform aggregations on our data, such as calculating means, sums, and other summary statistics. Additionally, we can group data for more advanced analysis.\n",
        "\n",
        "1. **Aggregation**: Operations like `mean()`, `sum()`, `count()`, etc., can be applied to columns of data.\n",
        "2. **Grouping**: We can split data into groups based on some criteria, apply a function to each group, and combine the results.\n",
        "\n",
        "    - **Syntax**: Use the `groupby()` method to group data by one or more columns, and then apply aggregation functions like `mean()`, `sum()`, `count()`, etc.\n",
        "    - **Example**:\n",
        "      - Group by a single column and calculate the mean: `df.groupby('Type')['Height'].mean()`\n",
        "      - Group by multiple columns and calculate the sum: `df.groupby(['Type', 'Year Built'])['Height'].sum()`\n",
        "      - Count the number of entries in each group: `df.groupby('Type').size()`\n",
        "\n",
        "    Grouping is particularly useful for summarizing data and identifying patterns within subsets of your dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "807e2841",
      "metadata": {},
      "source": [
        "#### Aggregation Functions\n",
        "\n",
        "In `pandas`, you can apply a wide range of aggregation functions directly to DataFrame columns (just like `sum()`). Here are the most common ones:\n",
        "\n",
        "##### Basic Aggregations\n",
        "\n",
        "- sum() – sum of values\n",
        "\n",
        "- mean() – average\n",
        "\n",
        "- median() – median\n",
        "\n",
        "- min() – minimum\n",
        "\n",
        "- max() – maximum\n",
        "\n",
        "- count() – number of non-null entries\n",
        "\n",
        "- nunique() – number of unique values\n",
        "\n",
        "- prod() – product of all values\n",
        "\n",
        "##### Statistical Aggregations\n",
        "\n",
        "- std() – standard deviation\n",
        "\n",
        "- var() – variance\n",
        "\n",
        "- sem() – standard error of the mean\n",
        "\n",
        "- skew() – skewness\n",
        "\n",
        "\n",
        "##### Logical and Index-based Aggregations\n",
        "\n",
        "- any() – returns True if any value is True\n",
        "\n",
        "- all() – returns True if all values are True\n",
        "\n",
        "- first() – first non-null value\n",
        "\n",
        "- last() – last non-null value\n",
        "\n",
        "- idxmin() – index of min value\n",
        "\n",
        "- idxmax() – index of max value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "409803d7",
      "metadata": {
        "id": "409803d7"
      },
      "outputs": [],
      "source": [
        "# Calculate mean of the 'Height' column\n",
        "height_mean = df['Height'].mean()\n",
        "print(height_mean)\n",
        "\n",
        "# Calculate sum of the 'Height' column\n",
        "height_sum = df['Height'].sum()\n",
        "print(height_sum)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2433fea3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate the standard deviation of the 'Height' column\n",
        "height_std = df['Height'].std()\n",
        "print(height_std)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "184b2582",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find the index of the maximum value in the 'Height' column\n",
        "max_height_index = df['Height'].idxmax()\n",
        "print(\"Index of maximum height:\", max_height_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "074486c6",
      "metadata": {},
      "source": [
        "#### `Groupby()`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fc2c8a0",
      "metadata": {},
      "source": [
        "Now lets' investigate grouping rows in `DataFrame` using `.groupby()`. For this purpose, we will use an augmented version of our dataset that includes landmarks from MIT and Stanford too."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe1b0213",
      "metadata": {},
      "outputs": [],
      "source": [
        "augmented_df = pd.read_csv(\"data/Augmented_Landmarks_DataFrame.csv\")\n",
        "augmented_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5be0392",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Group the DataFrame by the 'Type' column\n",
        "grouped = augmented_df.groupby('Type')\n",
        "\n",
        "# Iterate through each group and display its content\n",
        "for group_name, group_data in grouped:\n",
        "    print(f\"Group: {group_name}\")\n",
        "    display(group_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0983d2b",
      "metadata": {},
      "source": [
        "##### Grouping by One Column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba4ad015",
      "metadata": {},
      "outputs": [],
      "source": [
        "augmented_df.groupby('Type')[['Height']].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7113c10f",
      "metadata": {},
      "outputs": [],
      "source": [
        "augmented_df.groupby('Type')[['Height', 'Year Built']].mean()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb5ed813",
      "metadata": {},
      "source": [
        "##### Grouping by Multiple Columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84325c86",
      "metadata": {},
      "outputs": [],
      "source": [
        "augmented_df.groupby(['Type', 'Campus'])[['Height']].agg('max')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99bdcea9",
      "metadata": {},
      "source": [
        "#### Pivot Tables in `pandas`\n",
        "A pivot table is a powerful data summarization tool that allows you to reorganize and aggregate data in a `DataFrame`. It is particularly useful for analyzing and summarizing large datasets by grouping data and applying aggregation functions.\n",
        "\n",
        "**Syntax:**\n",
        "`pd.pivot_table(data, values='column_to_aggregate', index='row_index', columns='column_headers', aggfunc='aggregation_function')`\n",
        "\n",
        "1. **Index**: Rows of the pivot table, typically representing unique values from one or more columns.\n",
        "2. **Columns**: Columns of the pivot table, typically representing unique values from another column.\n",
        "3. **Values**: The data to be aggregated, typically numeric columns.\n",
        "4. **Aggregation Function**: The function applied to summarize the data, such as `mean`, `sum`, `count`, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "243226d6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a pivot table to summarize the average Height for each Type and Campus\n",
        "pivot_table = pd.pivot_table(\n",
        "    augmented_df,\n",
        "    index='Type',\n",
        "    columns='Campus',\n",
        "    values='Height',\n",
        "    aggfunc='max'\n",
        ")\n",
        "\n",
        "# Display the pivot table\n",
        "display(pivot_table)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2696b2b7",
      "metadata": {
        "vscode": {
          "languageId": "julia"
        }
      },
      "source": [
        "### Joining `DataFrames` in `pandas`\n",
        "\n",
        "Joining `DataFrames` is a common operation when working with multiple datasets. It allows you to combine data from different sources based on a common key or index. `pandas` provides several methods for joining `DataFrames`, including `merge()`, `join()`, and concatenation.\n",
        "\n",
        "#### Types of Joins:\n",
        "1. **Inner Join**: Returns only the rows with matching keys in both `DataFrames`.\n",
        "2. **Outer Join**: Returns all rows from both `DataFrames`, filling missing values with `NaN` where there is no match.\n",
        "3. **Left Join**: Returns all rows from the left DataFrame and matching rows from the right DataFrame.\n",
        "4. **Right Join**: Returns all rows from the right DataFrame and matching rows from the left DataFrame.\n",
        "\n",
        "Below, we demonstrate how to join two `DataFrames`: `landmarks` and `event_data`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de8b1161",
      "metadata": {},
      "outputs": [],
      "source": [
        "landmarks = df.copy()\n",
        "landmarks"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6df9f088",
      "metadata": {},
      "source": [
        "##### Inner Join"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65a160aa",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reset the index of event_data without keeping the old index as a column\n",
        "event_data.reset_index(inplace=True)\n",
        "event_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61f77205",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform an inner join using the join method\n",
        "result_join_inner = landmarks.join(event_data.set_index('Year'), on='Year Built', how='inner')\n",
        "\n",
        "# Display the result\n",
        "result_join_inner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a6d574e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform an inner join using the merge function\n",
        "result_merge_inner = landmarks.merge(event_data, how='inner', left_on='Year Built', right_on='Year')\n",
        "\n",
        "# Display the result\n",
        "display(result_merge_inner)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f50210c4",
      "metadata": {},
      "source": [
        "##### Outer Join"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa7f2780",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform an outer join\n",
        "result_join_outer = landmarks.join(event_data.set_index('Year'), on='Year Built', how='outer')\n",
        "\n",
        "# Display the result\n",
        "display(result_join_outer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b030f33f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform an outer join using the merge function\n",
        "result_merge_outer = landmarks.merge(event_data, left_on='Year Built', right_on='Year', how='outer')\n",
        "\n",
        "# Display the result\n",
        "display(result_merge_outer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df6c8905",
      "metadata": {},
      "source": [
        "-------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bba4ebc",
      "metadata": {},
      "source": [
        "## Visualization\n",
        "\n",
        "Building visualization is an important part of machine learning. In this notebook, we will explore how to create interactive visualizations using Plotly, a powerful library for creating dynamic and engaging plots.\n",
        "\n",
        "Critically, we will learn how to use Plotly to visualize data in a way that helps us debug machine learning algorithms and communicate results effectively.\n",
        "\n",
        "There are many different visualization libraries available in Python, but Plotly stands out for its interactivity and ease of use. It allows us to create plots that can be easily shared and embedded in web applications.  However, you will likely also encounter Matplotlib and its more friendly Seaborn wrapper. Matplotlib is a more traditional plotting library that is widely used in the Python community. It is a good choice for creating static plots, but it does not have the same level of interactivity as Plotly. Seaborn is a higher-level interface to Matplotlib that makes it easier to create complex visualizations with less code.\n",
        "\n",
        "We have chosen to prioritize Plotly in this course because we believe it is important to be able to interact with your data as you explore it.  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81ab23b8",
      "metadata": {},
      "source": [
        "### Toy Data\n",
        "\n",
        "Here we will use the [auto-mpg dataset](https://archive.ics.uci.edu/ml/datasets/auto+mpg) from the UCI Machine Learning Repository, which contains information about various cars, including their miles per gallon (MPG), number of cylinders, horsepower, and more. This dataset is commonly used for regression tasks in machine learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "907a1927",
      "metadata": {},
      "outputs": [],
      "source": [
        "mpg = pd.read_csv(\"hf://datasets/scikit-learn/auto-mpg/auto-mpg.csv\")\n",
        "mpg['origin'] = mpg['origin'].map({1: 'USA', 2: 'Europe', 3: 'Japan'})\n",
        "mpg"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9145ed4",
      "metadata": {},
      "source": [
        "### Matplotlib and Seaborn\n",
        "\n",
        "#### Matplotlib\n",
        "Matplotlib is a versatile Python library for creating static, animated, and interactive visualizations. It offers a low-level interface for highly customizable plots, suitable for publication-quality visualizations.\n",
        "\n",
        "##### Types of Plots:\n",
        "- Line Plots\n",
        "- Scatter Plots\n",
        "- Bar Charts\n",
        "- Histograms\n",
        "- Box Plots\n",
        "- Heatmaps\n",
        "\n",
        "#### Seaborn\n",
        "Seaborn is a high-level interface built on top of Matplotlib, designed for statistical data visualization. It provides an intuitive interface and aesthetically pleasing default styles, working seamlessly with Pandas DataFrames.\n",
        "\n",
        "##### Types of Plots:\n",
        "- Relational Plots (scatter, line)\n",
        "- Categorical Plots (bar, box, violin, swarm)\n",
        "- Distribution Plots (histograms, KDE, rug)\n",
        "- Regression Plots\n",
        "- Heatmaps\n",
        "\n",
        "Matplotlib offers more control, while Seaborn simplifies the creation of visually appealing plots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d3ebf05",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Line Plot\n",
        "sns.lineplot(data=mpg, x='model year', y='mpg', hue='origin', marker='o')\n",
        "plt.title('Average MPG by Model Year and Origin')\n",
        "plt.xlabel('Model Year')\n",
        "plt.ylabel('Miles Per Gallon (MPG)')\n",
        "plt.legend(title='Origin')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62dae7d4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scatter Plot\n",
        "sns.scatterplot(data=mpg, x='weight', y='mpg', hue='origin')\n",
        "plt.title('MPG vs. Weight by Origin')\n",
        "plt.xlabel('Weight (lbs)')\n",
        "plt.ylabel('Miles Per Gallon (MPG)')\n",
        "plt.legend(title='Origin')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86a59e21",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bar Chart\n",
        "mpg.groupby('origin')['mpg'].mean().plot(kind='bar', color=['blue', 'orange', 'green'])\n",
        "plt.title('Average MPG by Origin')\n",
        "plt.ylabel('Average MPG')\n",
        "plt.xlabel('Origin')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0aaf65f0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Histogram\n",
        "sns.histplot(data=mpg, x='mpg', hue='origin', element='step', stat='count', common_norm=False)\n",
        "plt.title('MPG Distribution by Origin')\n",
        "plt.xlabel('Miles Per Gallon (MPG)')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d53c6010",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Box Plot\n",
        "sns.boxplot(data=mpg, x='origin', y='mpg', hue='origin', palette='Set2')\n",
        "plt.title('MPG Distribution by Origin')\n",
        "plt.xlabel('Origin')\n",
        "plt.ylabel('Miles Per Gallon (MPG)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99e6fb99",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Heatmap\n",
        "corr = mpg[['mpg', 'cylinders', 'displacement', 'weight', 'acceleration']].corr()\n",
        "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1d13323",
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.scatterplot(data=mpg, x='weight', y='mpg', hue='origin', size='cylinders')\n",
        "plt.title('MPG by Weight and Origin')\n",
        "plt.xlabel('Weight (lbs)')\n",
        "plt.ylabel('Miles Per Gallon (MPG)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e564c9cb",
      "metadata": {},
      "source": [
        "## Value of Interactive Visualizations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fd5ca08",
      "metadata": {},
      "source": [
        "Static Visualizations are great for presenting results, but they can be limiting when it comes to exploring data. Interactive visualizations allow us to:\n",
        "- **Zoom and Pan**: Focus on specific areas of the plot.\n",
        "- **Hover for Details**: Get more information about specific data points.\n",
        "- **Filter Data**: Select subsets of data to visualize.\n",
        "- **Change Parameters**: Adjust parameters dynamically to see how they affect the visualization.\n",
        "These features make it easier to understand complex datasets and identify patterns or anomalies."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb8f38bb",
      "metadata": {},
      "source": [
        "### Three Modes for Plotly \n",
        "\n",
        "There are three modes for using Plotly that we will explore in this course:\n",
        "\n",
        "1. **Pandas Plotting**: A convenient interface for creating Plotly visualizations directly from Pandas DataFrames. It simplifies the process of generating plots from tabular data.\n",
        "2. **Plotly Express**: A high-level interface for creating plots with minimal code. It is ideal for quick visualizations and exploratory data analysis.  This is similar to the Seaborn interface for Matplotlib, which is a higher-level interface to Matplotlib that makes it easier to create complex visualizations with less code. Like Pandas Plotting, it is designed to work seamlessly with Pandas DataFrames and provides a simple API for creating a wide range of visualizations.\n",
        "3. **Graph Objects**: A more flexible and powerful interface that allows for fine-grained control over the appearance and behavior of plots. It is suitable for creating complex visualizations and custom layouts.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93b5ef85",
      "metadata": {},
      "source": [
        "#### Using `pandas` Plotting\n",
        "\n",
        "To use Plotly in `pandas`, you need to set the plotting backend to Plotly. This allows you to use the `plot` method on `pandas` `DataFrames` to create interactive plots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b656f5c2",
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.set_option('plotting.backend', 'plotly')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7f817c5",
      "metadata": {},
      "source": [
        "Now we can use the `plot` method on our `DataFrame` to create interactive plots. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9997c369",
      "metadata": {},
      "outputs": [],
      "source": [
        "mpg.plot(\n",
        "    kind='scatter',\n",
        "    x='weight', y='mpg', color='origin', size='cylinders',\n",
        "    title='MPG vs. Weight by Origin',\n",
        "    width=800, height=600)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9564a61a",
      "metadata": {},
      "source": [
        "Notice how we specify the `kind` of plot as well as how the data should be mapped to the axes, color, and size.  This is an interactive plot so you can mouse over the points to see more information. You can double and tripple click on the legend to hide and show different series. You can also zoom in and out of the plot by clicking and dragging on the plot area. Here we also set the width and height of the plot to make it larger and more readable.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "173075af",
      "metadata": {},
      "source": [
        "#### Creating an Interactive Scatter Plot with Plotly Express\n",
        "\n",
        "Plotly express is closely related to Pandas Plotting, but it is a separate library that provides a high-level interface for creating plots. It is designed to work seamlessly with `pandas` `DataFrames` and provides a simple API for creating a wide range of visualizations. Plotly express offers more flexibility and customization options than `pandas` plotting, making it a powerful tool for creating complex visualizations. \n",
        "\n",
        "**Key components:**\n",
        "\n",
        "1. **`px.scatter`**: Generates a scatter plot to visualize relationships between two numerical variables.\n",
        "2. **Parameters**:\n",
        "    - **`mpg`**: Dataset containing car information.\n",
        "    - **`x='weight'`**: X-axis represents car weight.\n",
        "    - **`y='mpg'`**: Y-axis represents miles per gallon.\n",
        "    - **`color='origin'`**: Groups points by car origin.\n",
        "    - **`size='cylinders'`**: Marker size reflects the number of cylinders.\n",
        "    - **`size_max=12`**: Limits marker size.\n",
        "    - **`hover_data=mpg.columns`**: Displays all dataset columns on hover.\n",
        "    - **`title='MPG vs. Weight by Origin'`**: Adds a plot title.\n",
        "    - **`labels={'weight': 'Weight (lbs)', 'mpg': 'Miles Per Gallon (MPG)'}`**: Customizes axis labels.\n",
        "    - **`width=800, height=600`**: Sets plot dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4bac4c0",
      "metadata": {},
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "\n",
        "px.scatter(mpg, x='weight', y='mpg', color='origin', \n",
        "           size='cylinders', size_max=12,\n",
        "           hover_data=mpg.columns,\n",
        "           title='MPG vs. Weight by Origin',\n",
        "           labels={'weight': 'Weight (lbs)', 'mpg': 'Miles Per Gallon (MPG)'},\n",
        "           width=800, height=600)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74993572",
      "metadata": {},
      "source": [
        "All the basic plotting functions in `pandas` and `plotly express` return `Figure` objects, which can be further customized using the methods available in the `plotly.graph_objects` module. We can use `update_layout` to update some parameters in the figure.\n",
        "\n",
        "**Key Components:**\n",
        "\n",
        "1. **Parameters**:\n",
        "    - **`animation_frame='model year'`**: Animates the plot over the `model year` column, showing changes over time.\n",
        "\n",
        "2. **`fig.update_layout`**:\n",
        "    - **`xaxis_title` and `yaxis_title`**: Sets the axis titles.\n",
        "    - **`xaxis_range` and `yaxis_range`**: Defines the range of the x and y axes.\n",
        "    - **`legend_title_text`**: Sets the title for the legend."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73184ad4",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = px.scatter(mpg, x='weight', y='mpg', color='origin',\n",
        "                 hover_data=mpg.columns,\n",
        "                 animation_frame='model year', \n",
        "                 title='MPG vs. Weight by Origin',\n",
        "                 labels={'weight': 'Weight (lbs)', 'mpg': 'Miles Per Gallon (MPG)'},\n",
        "                 width=800, height=600)\n",
        "fig.update_layout(\n",
        "    xaxis_title='Weight (lbs)',\n",
        "    yaxis_title='Miles Per Gallon (MPG)',\n",
        "    xaxis_range=[1500, 5000],\n",
        "    yaxis_range=[10, 50],\n",
        "    legend_title_text='Origin',\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d8661ab",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = mpg.plot(\n",
        "    kind='scatter',\n",
        "    x='weight', y='mpg', color='origin', size='cylinders',\n",
        "    title='MPG vs. Weight by Origin',\n",
        "    width=800, height=600)\n",
        "\n",
        "# change to the style\n",
        "fig.update_layout(template='plotly_dark')\n",
        "# fig.update_layout(template='plotly_white')\n",
        "# fig.update_layout(template='ggplot2')\n",
        "# fig.update_layout(template='seaborn')\n",
        "fig.update_layout(xaxis_title='Weight (lbs)',\n",
        "                  yaxis_title='Miles per Gallon (MPG)',\n",
        "                  legend_title='Origin')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e118d62",
      "metadata": {},
      "source": [
        "We can also save plots to HTML files, which can be shared and embedded in web applications. This is useful for creating interactive reports and dashboards.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71524e05",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig.write_html('mpg_scatter.html', include_plotlyjs='cdn')\n",
        "fig.write_image('mpg_scatter.png', scale=2, width=800, height=600)\n",
        "fig.write_image('mpg_scatter.pdf', scale=2, width=800, height=600)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca5862ee",
      "metadata": {},
      "source": [
        "The figure object is made of two key components: \n",
        "- the **data** and \n",
        "- the **layout**. \n",
        "\n",
        "The data is a list of traces, which are the individual plots that make up the figure. The layout is a dictionary that contains information about the appearance of the plot, such as the title, axis labels, and legend."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31a00a5e",
      "metadata": {},
      "outputs": [],
      "source": [
        "display(fig.data)\n",
        "display(fig.layout)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c1899ee",
      "metadata": {},
      "source": [
        "Just as before we get back a `Figure` object that we can further customize."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fe70ffc",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = px.scatter(mpg, x='weight', y='mpg', color='origin', size='cylinders',\n",
        "                 title='MPG vs. Weight by Origin',\n",
        "                 width=800, height=600, \n",
        "                 template='plotly_dark')\n",
        "# change the marker symbol for the USA trace\n",
        "fig.update_traces(marker=dict(symbol=\"square\"), selector=dict(name=\"USA\")) \n",
        "# you can also just modify the data dictionary directly\n",
        "#fig.data[0]['marker']['symbol'] = \"square\"\n",
        "\n",
        "# change formatting (layout) of the figure\n",
        "fig.update_layout(font=dict(family=\"Courier New, monospace\", size=16))\n",
        "# You can also refer to the font family and size directly\n",
        "fig.update_layout(font_family=\"Courier New, monospace\", font_size=16)\n",
        "fig"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00397821",
      "metadata": {},
      "source": [
        "### Using Plotly Graphics Objects\n",
        "\n",
        "The Graphics objects are a more flexible and powerful interface that allows for fine-grained control over the appearance and behavior of plots. It is suitable for creating complex visualizations and custom layouts.\n",
        "\n",
        "A Figure Graphic Object is composed of:\n",
        "- **Data:** A list of traces (e.g., Scatter, Lines, Annotations)\n",
        "- **Layout:** A dictionary describing the overall layout (e.g., title, axis properties, …)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8809746a",
      "metadata": {},
      "outputs": [],
      "source": [
        "from plotly import graph_objects as go"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "381d292b",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = go.Figure()\n",
        "max_size = 20\n",
        "\n",
        "# Iterate over unique origins and create a scatter trace for each\n",
        "for i, origin in enumerate(mpg['origin'].unique()):\n",
        "    # Filter the DataFrame for the current origin\n",
        "    subset = mpg[mpg['origin'] == origin]\n",
        "    marker_sizes = max_size*subset['cylinders']/subset['cylinders'].max()\n",
        "    # Create a hover text for each point\n",
        "    hover_text = (\n",
        "            subset['origin'] + \"<br>\"\n",
        "                  \"Weight: \" + subset['weight'].astype(str) + \"<br>\"\n",
        "                  \"MPG: \" + subset['mpg'].astype(str) + \"<br>\"\n",
        "                  \"Cylinders: \" + subset['cylinders'].astype(str))\n",
        "    # add a trace to the figure\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=subset['weight'], y=subset['mpg'],\n",
        "            mode='markers',\n",
        "            name=origin,\n",
        "            marker=dict(size=marker_sizes, color=i),\n",
        "            text=hover_text,\n",
        "        )\n",
        "    )\n",
        "fig.add_annotation(\n",
        "    text=\"Data source: Auto MPG dataset\",\n",
        "    xref=\"paper\", yref=\"paper\",\n",
        "    x=0, y=-0.1,\n",
        "    showarrow=False,\n",
        "    font=dict(size=12, color=\"gray\")\n",
        ")\n",
        "fig.update_layout(\n",
        "    title='MPG vs. Weight by Origin',\n",
        "    xaxis_title='Weight (lbs)',\n",
        "    yaxis_title='Miles per Gallon (MPG)',\n",
        "    width=800, height=600,\n",
        "    template='plotly_white',\n",
        "    font_family=\"Times\", font_size=16,\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4770ee16",
      "metadata": {},
      "source": [
        "### Visualizing Different Kinds of Data\n",
        "\n",
        "Now that we have seen the basics of using Plotly, let's explore how to visualize different kinds of data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "077441be",
      "metadata": {},
      "source": [
        "#### Histograms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90b37ce0",
      "metadata": {},
      "outputs": [],
      "source": [
        "px.histogram(mpg, x='mpg', facet_row='origin')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb97f382",
      "metadata": {},
      "outputs": [],
      "source": [
        "mpg.hist(x='mpg', color='origin', bins=10, barmode='overlay')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8c91a67",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = mpg.hist(x='mpg', color='origin', bins=10, facet_row='origin',\n",
        "         title='MPG Distribution by Origin',\n",
        "         width=800, height=600)\n",
        "fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89d9dd34",
      "metadata": {},
      "outputs": [],
      "source": [
        "mpg['make'] =mpg['car name'].str.split(' ').str[0]\n",
        "mpg.plot(kind='bar',\n",
        "         x='make', color='origin', \n",
        "         hover_data=['mpg', 'cylinders', 'car name'],\n",
        "         title='Average MPG by Make and Origin',\n",
        "         width=800, height=600)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b649e2a",
      "metadata": {},
      "source": [
        "#### Scatter and Line Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68d71412",
      "metadata": {},
      "outputs": [],
      "source": [
        "yearly_mpg = (\n",
        "    mpg\n",
        "    .groupby(['origin', 'model year'])\n",
        "    [['mpg', 'displacement', 'weight']]\n",
        "    .mean().reset_index()\n",
        ")\n",
        "yearly_mpg.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2910551a",
      "metadata": {},
      "outputs": [],
      "source": [
        "px.scatter(yearly_mpg, x='model year', y='mpg', color='origin',\n",
        "        title='Average MPG by Model Year and Origin',\n",
        "        width=800, height=600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d48f7455",
      "metadata": {},
      "outputs": [],
      "source": [
        "px.line(yearly_mpg, x='model year', y='mpg', color='origin',\n",
        "        markers=True,\n",
        "        title='Average MPG by Model Year and Origin',\n",
        "        width=800, height=600)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "cs189",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
